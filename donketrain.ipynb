{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WUepNQ2hRdeg",
        "outputId": "1c6cdaf6-7d72-48b8-a13e-e65a0ac88a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n",
            "Cloning into 'donkeycar'...\n",
            "remote: Enumerating objects: 16443, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 16443 (delta 0), reused 0 (delta 0), pack-reused 16440 (from 2)\u001b[K\n",
            "Receiving objects: 100% (16443/16443), 90.14 MiB | 32.17 MiB/s, done.\n",
            "Resolving deltas: 100% (10913/10913), done.\n",
            "/content/donkeycar\n",
            "Note: switching to '5.1.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at bd5521f9 Set release version\n",
            "Obtaining file:///content/donkeycar\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (11.1.0)\n",
            "Collecting docopt (from donkeycar==5.1.0)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (6.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (2.32.3)\n",
            "Requirement already satisfied: PrettyTable in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (3.12.0)\n",
            "Collecting paho-mqtt (from donkeycar==5.1.0)\n",
            "  Downloading paho_mqtt-2.1.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting simple_pid (from donkeycar==5.1.0)\n",
            "  Downloading simple_pid-2.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting progress (from donkeycar==5.1.0)\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyfiglet (from donkeycar==5.1.0)\n",
            "  Downloading pyfiglet-1.0.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (5.9.5)\n",
            "Collecting pynmea2 (from donkeycar==5.1.0)\n",
            "  Downloading pynmea2-1.19.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyserial (from donkeycar==5.1.0)\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting utm (from donkeycar==5.1.0)\n",
            "  Downloading utm-0.7.0.tar.gz (8.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (2.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (6.0.2)\n",
            "Collecting tensorflow==2.15.* (from donkeycar==5.1.0)\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (3.10.0)\n",
            "Collecting kivy (from donkeycar==5.1.0)\n",
            "  Downloading Kivy-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (5.24.1)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from donkeycar==5.1.0) (1.4.20)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.*->donkeycar==5.1.0)\n",
            "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.*->donkeycar==5.1.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.*->donkeycar==5.1.0) (1.69.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.*->donkeycar==5.1.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.*->donkeycar==5.1.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.*->donkeycar==5.1.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations->donkeycar==5.1.0) (1.13.1)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from albumentations->donkeycar==5.1.0) (2.10.5)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.11/dist-packages (from albumentations->donkeycar==5.1.0) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.11/dist-packages (from albumentations->donkeycar==5.1.0) (0.2.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->donkeycar==5.1.0) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.19->albumentations->donkeycar==5.1.0) (3.11.3)\n",
            "Collecting Kivy-Garden>=0.1.4 (from kivy->donkeycar==5.1.0)\n",
            "  Downloading Kivy_Garden-0.1.5-py3-none-any.whl.metadata (159 bytes)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.11/dist-packages (from kivy->donkeycar==5.1.0) (0.21.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from kivy->donkeycar==5.1.0) (2.18.0)\n",
            "Collecting filetype (from kivy->donkeycar==5.1.0)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->donkeycar==5.1.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->donkeycar==5.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->donkeycar==5.1.0) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->donkeycar==5.1.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->donkeycar==5.1.0) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->donkeycar==5.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->donkeycar==5.1.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->donkeycar==5.1.0) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->donkeycar==5.1.0) (9.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from PrettyTable->donkeycar==5.1.0) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->donkeycar==5.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->donkeycar==5.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->donkeycar==5.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->donkeycar==5.1.0) (2024.12.14)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.*->donkeycar==5.1.0) (0.45.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations->donkeycar==5.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations->donkeycar==5.1.0) (2.27.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.*->donkeycar==5.1.0) (3.2.2)\n",
            "Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m868.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Kivy-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.0/23.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paho_mqtt-2.1.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyfiglet-1.0.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynmea2-1.19.0-py3-none-any.whl (30 kB)\n",
            "Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simple_pid-2.0.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Kivy_Garden-0.1.5-py3-none-any.whl (4.6 kB)\n",
            "Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: donkeycar, docopt, progress, utm\n",
            "  Building editable for donkeycar (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for donkeycar: filename=donkeycar-5.1.0-0.editable-py3-none-any.whl size=6222 sha256=3238ab0d8b492760604a3e1be15c17ac5adc74df9d634854063b0eaf7c68f7cb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c9r18u1c/wheels/06/5f/3f/90325e2026a738feaab927bf0a894b538380ca5de7ded26f4b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=3bd8e20282c3c68edbd03ec99e3da8af6024cf03a10647ad933898d5c971cde5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9613 sha256=8bb8e45f57a16ffa57ea32546c1b7dd0e1c446977acb6bb3eb0b69f7c6fe3c63\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b9/86/f1bcc2a1de592673c4192d9459c0da1100d70212f38b6bd2a4\n",
            "  Building wheel for utm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utm: filename=utm-0.7.0-py3-none-any.whl size=6085 sha256=96fec447983b9e481e159af18554379d319e8427eb9903b4c5c5a5b8c8fa6fb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/30/59/0a0f4976bbec8d13eb19b8ae0d691aeb9499463fb2924bf6d8\n",
            "Successfully built donkeycar docopt progress utm\n",
            "Installing collected packages: utm, pyserial, pynmea2, progress, filetype, docopt, wrapt, tensorflow-estimator, simple_pid, pyfiglet, paho-mqtt, ml-dtypes, keras, Kivy-Garden, kivy, donkeycar, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Kivy-Garden-0.1.5 docopt-0.6.2 donkeycar-5.1.0 filetype-1.2.0 keras-2.15.0 kivy-2.3.1 ml-dtypes-0.3.2 paho-mqtt-2.1.0 progress-1.6 pyfiglet-1.0.2 pynmea2-1.19.0 pyserial-3.5 simple_pid-2.0.1 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 utm-0.7.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "ml_dtypes",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "92de477e4a134028b609b9f012191d67"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__) # tf version should be > 2.9 and <=2.15\n",
        "!git clone https://github.com/autorope/donkeycar.git\n",
        "%cd /content/donkeycar\n",
        "!git checkout 5.1.0 # DonkeyCar v5.1.0\n",
        "!pip3 install -e .[pc]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!donkey createcar --path /content/mycar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxu2MIthTFyl",
        "outputId": "983d5103-2dfd-4100-8e81-ed12f6cb0f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________             ______                   _________              \n",
            "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
            "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
            "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
            "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
            "                                 /____/                              \n",
            "\n",
            "using donkey v5.1.0 ...\n",
            "Creating car folder: /content/mycar\n",
            "making dir  /content/mycar\n",
            "Creating data & model folders.\n",
            "making dir  /content/mycar/models\n",
            "making dir  /content/mycar/data\n",
            "making dir  /content/mycar/logs\n",
            "Copying car application template: complete\n",
            "Copying car config defaults. Adjust these before starting your car.\n",
            "Copying train script. Adjust these before starting your car.\n",
            "Copying calibrate script. Adjust these before starting your car.\n",
            "Copying my car config overrides\n",
            "Donkey setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Connect to a GD folder\n",
        "drive.mount('/content/drive')\n",
        "# Default folder of Colab Notebook files\n",
        "path = \"/content/drive/MyDrive/LYFTCAR/newTubs/\" # TODO: Modify the path if necessary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc-RAtgmTJr-",
        "outputId": "c0e0981e-16e4-4e8e-8bc3-8c754ed7f1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tub_names = [\"tub_137_25-01-14\", \"tub_141_25-01-15\"]"
      ],
      "metadata": {
        "id": "qQQvBuK6TUWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mycar/data\n",
        "for tub_name in tub_names:\n",
        "  tub = path + tub_name\n",
        "  source_path = tub\n",
        "  destination_path = \"/content/mycar/data/\" + tub_name\n",
        "\n",
        "  !cp {source_path}.tar.gz .\n",
        "  # And untar it to the right place\n",
        "  !tar -xzf {tub_name}.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U6qODFUUR4g",
        "outputId": "578cccde-8435-4186-ad1c-cbead7cb7ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mycar/data\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mycar\n",
        "\n",
        "model_name = \"small_model\"\n",
        "\n",
        "train_data = \"\"\n",
        "for tub_name in tub_names:\n",
        "  train_data += \"./data/\" + tub_name + \" \"\n",
        "  print(tub_name)\n",
        "!donkey train --tub {train_data} --model models/{model_name}\".h5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A_vpOVEUUTT",
        "outputId": "76166317-db94-4966-910f-f8d4411c0ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mycar\n",
            "tub_137_25-01-14\n",
            "tub_141_25-01-15\n",
            "________             ______                   _________              \n",
            "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
            "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
            "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
            "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
            "                                 /____/                              \n",
            "\n",
            "using donkey v5.1.0 ...\n",
            "INFO:donkeycar.config:loading config file: ./config.py\n",
            "INFO:donkeycar.config:loading personal config over-rides from ./myconfig.py\n",
            "2025-01-21 00:22:10.078063: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-21 00:22:10.078136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-21 00:22:10.082198: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-21 00:22:12.466927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "WARNING:donkeycar.pipeline.database:No model database found at /content/mycar/models/database.json\n",
            "INFO:donkeycar.utils:get_model_by_type: model type is: linear\n",
            "INFO:donkeycar.parts.keras:Created KerasLinear with interpreter: KerasInterpreter\n",
            "Model: \"linear\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " img_in (InputLayer)         [(None, 120, 160, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 58, 78, 24)           1824      ['img_in[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 58, 78, 24)           0         ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 27, 37, 32)           19232     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 27, 37, 32)           0         ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 12, 17, 64)           51264     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 12, 17, 64)           0         ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 10, 15, 64)           36928     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 10, 15, 64)           0         ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 8, 13, 64)            36928     ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 8, 13, 64)            0         ['conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " flattened (Flatten)         (None, 6656)                 0         ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 100)                  665700    ['flattened[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 100)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 50)                   5050      ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 50)                   0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " n_outputs0 (Dense)          (None, 1)                    51        ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " n_outputs1 (Dense)          (None, 1)                    51        ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 817028 (3.12 MB)\n",
            "Trainable params: 817028 (3.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "INFO:donkeycar.parts.datastore_v2:Found datastore at /content/mycar/data/tub_137_25-01-14\n",
            "INFO:donkeycar.parts.datastore_v2:Using last catalog /content/mycar/data/tub_137_25-01-14/catalog_18.catalog\n",
            "INFO:donkeycar.parts.datastore_v2:Found datastore at /content/mycar/data/tub_141_25-01-15\n",
            "INFO:donkeycar.parts.datastore_v2:Using last catalog /content/mycar/data/tub_141_25-01-15/catalog_9.catalog\n",
            "INFO:donkeycar.pipeline.types:Loading tubs from paths ['./data/tub_137_25-01-14', './data/tub_141_25-01-15']\n",
            "INFO:donkeycar.pipeline.training:Records # Training 22216\n",
            "INFO:donkeycar.pipeline.training:Records # Validation 5554\n",
            "INFO:donkeycar.parts.tub_v2:Closing tub ./data/tub_137_25-01-14\n",
            "INFO:donkeycar.parts.datastore_v2:Closing manifest /content/mycar/data/tub_137_25-01-14\n",
            "INFO:donkeycar.parts.tub_v2:Closing tub ./data/tub_141_25-01-15\n",
            "INFO:donkeycar.parts.datastore_v2:Closing manifest /content/mycar/data/tub_141_25-01-15\n",
            "INFO:donkeycar.parts.image_transformations:Creating ImageTransformations []\n",
            "INFO:donkeycar.parts.image_transformations:Creating ImageTransformations []\n",
            "INFO:donkeycar.parts.image_transformations:Creating ImageTransformations []\n",
            "INFO:donkeycar.parts.image_transformations:Creating ImageTransformations []\n",
            "INFO:donkeycar.pipeline.training:Train with image caching: True\n",
            "INFO:donkeycar.parts.keras:////////// Starting training //////////\n",
            "Epoch 1/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.1448 - n_outputs0_loss: 0.1020 - n_outputs1_loss: 0.0429\n",
            "Epoch 1: val_loss improved from inf to 0.12785, saving model to /content/mycar/models/small_model.h5\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "174/174 [==============================] - 361s 2s/step - loss: 0.1448 - n_outputs0_loss: 0.1020 - n_outputs1_loss: 0.0429 - val_loss: 0.1278 - val_n_outputs0_loss: 0.0977 - val_n_outputs1_loss: 0.0301\n",
            "Epoch 2/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.1161 - n_outputs0_loss: 0.0944 - n_outputs1_loss: 0.0217\n",
            "Epoch 2: val_loss improved from 0.12785 to 0.11202, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 370s 2s/step - loss: 0.1161 - n_outputs0_loss: 0.0944 - n_outputs1_loss: 0.0217 - val_loss: 0.1120 - val_n_outputs0_loss: 0.0956 - val_n_outputs1_loss: 0.0164\n",
            "Epoch 3/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.1069 - n_outputs0_loss: 0.0878 - n_outputs1_loss: 0.0191\n",
            "Epoch 3: val_loss improved from 0.11202 to 0.09840, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 375s 2s/step - loss: 0.1069 - n_outputs0_loss: 0.0878 - n_outputs1_loss: 0.0191 - val_loss: 0.0984 - val_n_outputs0_loss: 0.0837 - val_n_outputs1_loss: 0.0147\n",
            "Epoch 4/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0954 - n_outputs0_loss: 0.0777 - n_outputs1_loss: 0.0177\n",
            "Epoch 4: val_loss improved from 0.09840 to 0.08314, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 362s 2s/step - loss: 0.0954 - n_outputs0_loss: 0.0777 - n_outputs1_loss: 0.0177 - val_loss: 0.0831 - val_n_outputs0_loss: 0.0693 - val_n_outputs1_loss: 0.0139\n",
            "Epoch 5/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0852 - n_outputs0_loss: 0.0687 - n_outputs1_loss: 0.0166\n",
            "Epoch 5: val_loss improved from 0.08314 to 0.07378, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 370s 2s/step - loss: 0.0852 - n_outputs0_loss: 0.0687 - n_outputs1_loss: 0.0166 - val_loss: 0.0738 - val_n_outputs0_loss: 0.0611 - val_n_outputs1_loss: 0.0127\n",
            "Epoch 6/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0775 - n_outputs0_loss: 0.0623 - n_outputs1_loss: 0.0152\n",
            "Epoch 6: val_loss improved from 0.07378 to 0.06852, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 351s 2s/step - loss: 0.0775 - n_outputs0_loss: 0.0623 - n_outputs1_loss: 0.0152 - val_loss: 0.0685 - val_n_outputs0_loss: 0.0577 - val_n_outputs1_loss: 0.0109\n",
            "Epoch 7/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0739 - n_outputs0_loss: 0.0600 - n_outputs1_loss: 0.0139\n",
            "Epoch 7: val_loss improved from 0.06852 to 0.06677, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 371s 2s/step - loss: 0.0739 - n_outputs0_loss: 0.0600 - n_outputs1_loss: 0.0139 - val_loss: 0.0668 - val_n_outputs0_loss: 0.0574 - val_n_outputs1_loss: 0.0094\n",
            "Epoch 8/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0714 - n_outputs0_loss: 0.0583 - n_outputs1_loss: 0.0131\n",
            "Epoch 8: val_loss improved from 0.06677 to 0.06484, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 364s 2s/step - loss: 0.0714 - n_outputs0_loss: 0.0583 - n_outputs1_loss: 0.0131 - val_loss: 0.0648 - val_n_outputs0_loss: 0.0563 - val_n_outputs1_loss: 0.0086\n",
            "Epoch 9/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0682 - n_outputs0_loss: 0.0562 - n_outputs1_loss: 0.0120\n",
            "Epoch 9: val_loss improved from 0.06484 to 0.06317, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 335s 2s/step - loss: 0.0682 - n_outputs0_loss: 0.0562 - n_outputs1_loss: 0.0120 - val_loss: 0.0632 - val_n_outputs0_loss: 0.0546 - val_n_outputs1_loss: 0.0086\n",
            "Epoch 10/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0662 - n_outputs0_loss: 0.0548 - n_outputs1_loss: 0.0113\n",
            "Epoch 10: val_loss improved from 0.06317 to 0.06130, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 357s 2s/step - loss: 0.0662 - n_outputs0_loss: 0.0548 - n_outputs1_loss: 0.0113 - val_loss: 0.0613 - val_n_outputs0_loss: 0.0541 - val_n_outputs1_loss: 0.0072\n",
            "Epoch 11/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0650 - n_outputs0_loss: 0.0541 - n_outputs1_loss: 0.0109\n",
            "Epoch 11: val_loss improved from 0.06130 to 0.06070, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 332s 2s/step - loss: 0.0650 - n_outputs0_loss: 0.0541 - n_outputs1_loss: 0.0109 - val_loss: 0.0607 - val_n_outputs0_loss: 0.0534 - val_n_outputs1_loss: 0.0073\n",
            "Epoch 12/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0648 - n_outputs0_loss: 0.0544 - n_outputs1_loss: 0.0104\n",
            "Epoch 12: val_loss improved from 0.06070 to 0.06028, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 352s 2s/step - loss: 0.0648 - n_outputs0_loss: 0.0544 - n_outputs1_loss: 0.0104 - val_loss: 0.0603 - val_n_outputs0_loss: 0.0524 - val_n_outputs1_loss: 0.0079\n",
            "Epoch 13/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0620 - n_outputs0_loss: 0.0525 - n_outputs1_loss: 0.0095\n",
            "Epoch 13: val_loss did not improve from 0.06028\n",
            "174/174 [==============================] - 325s 2s/step - loss: 0.0620 - n_outputs0_loss: 0.0525 - n_outputs1_loss: 0.0095 - val_loss: 0.0607 - val_n_outputs0_loss: 0.0532 - val_n_outputs1_loss: 0.0075\n",
            "Epoch 14/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0621 - n_outputs0_loss: 0.0525 - n_outputs1_loss: 0.0095\n",
            "Epoch 14: val_loss improved from 0.06028 to 0.05808, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 352s 2s/step - loss: 0.0621 - n_outputs0_loss: 0.0525 - n_outputs1_loss: 0.0095 - val_loss: 0.0581 - val_n_outputs0_loss: 0.0516 - val_n_outputs1_loss: 0.0065\n",
            "Epoch 15/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0593 - n_outputs0_loss: 0.0503 - n_outputs1_loss: 0.0090\n",
            "Epoch 15: val_loss did not improve from 0.05808\n",
            "174/174 [==============================] - 334s 2s/step - loss: 0.0593 - n_outputs0_loss: 0.0503 - n_outputs1_loss: 0.0090 - val_loss: 0.0593 - val_n_outputs0_loss: 0.0519 - val_n_outputs1_loss: 0.0074\n",
            "Epoch 16/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0600 - n_outputs0_loss: 0.0509 - n_outputs1_loss: 0.0091\n",
            "Epoch 16: val_loss did not improve from 0.05808\n",
            "174/174 [==============================] - 351s 2s/step - loss: 0.0600 - n_outputs0_loss: 0.0509 - n_outputs1_loss: 0.0091 - val_loss: 0.0582 - val_n_outputs0_loss: 0.0517 - val_n_outputs1_loss: 0.0065\n",
            "Epoch 17/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0595 - n_outputs0_loss: 0.0509 - n_outputs1_loss: 0.0086\n",
            "Epoch 17: val_loss improved from 0.05808 to 0.05765, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 332s 2s/step - loss: 0.0595 - n_outputs0_loss: 0.0509 - n_outputs1_loss: 0.0086 - val_loss: 0.0577 - val_n_outputs0_loss: 0.0511 - val_n_outputs1_loss: 0.0065\n",
            "Epoch 18/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0571 - n_outputs0_loss: 0.0488 - n_outputs1_loss: 0.0083\n",
            "Epoch 18: val_loss did not improve from 0.05765\n",
            "174/174 [==============================] - 349s 2s/step - loss: 0.0571 - n_outputs0_loss: 0.0488 - n_outputs1_loss: 0.0083 - val_loss: 0.0582 - val_n_outputs0_loss: 0.0508 - val_n_outputs1_loss: 0.0075\n",
            "Epoch 19/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0566 - n_outputs0_loss: 0.0487 - n_outputs1_loss: 0.0079\n",
            "Epoch 19: val_loss improved from 0.05765 to 0.05583, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 328s 2s/step - loss: 0.0566 - n_outputs0_loss: 0.0487 - n_outputs1_loss: 0.0079 - val_loss: 0.0558 - val_n_outputs0_loss: 0.0492 - val_n_outputs1_loss: 0.0066\n",
            "Epoch 20/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0549 - n_outputs0_loss: 0.0476 - n_outputs1_loss: 0.0074\n",
            "Epoch 20: val_loss did not improve from 0.05583\n",
            "174/174 [==============================] - 329s 2s/step - loss: 0.0549 - n_outputs0_loss: 0.0476 - n_outputs1_loss: 0.0074 - val_loss: 0.0564 - val_n_outputs0_loss: 0.0500 - val_n_outputs1_loss: 0.0065\n",
            "Epoch 21/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0543 - n_outputs0_loss: 0.0468 - n_outputs1_loss: 0.0075\n",
            "Epoch 21: val_loss improved from 0.05583 to 0.05564, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 330s 2s/step - loss: 0.0543 - n_outputs0_loss: 0.0468 - n_outputs1_loss: 0.0075 - val_loss: 0.0556 - val_n_outputs0_loss: 0.0493 - val_n_outputs1_loss: 0.0063\n",
            "Epoch 22/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0541 - n_outputs0_loss: 0.0468 - n_outputs1_loss: 0.0073\n",
            "Epoch 22: val_loss did not improve from 0.05564\n",
            "174/174 [==============================] - 330s 2s/step - loss: 0.0541 - n_outputs0_loss: 0.0468 - n_outputs1_loss: 0.0073 - val_loss: 0.0561 - val_n_outputs0_loss: 0.0501 - val_n_outputs1_loss: 0.0059\n",
            "Epoch 23/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0532 - n_outputs0_loss: 0.0459 - n_outputs1_loss: 0.0074\n",
            "Epoch 23: val_loss did not improve from 0.05564\n",
            "174/174 [==============================] - 331s 2s/step - loss: 0.0532 - n_outputs0_loss: 0.0459 - n_outputs1_loss: 0.0074 - val_loss: 0.0570 - val_n_outputs0_loss: 0.0507 - val_n_outputs1_loss: 0.0063\n",
            "Epoch 24/100\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0525 - n_outputs0_loss: 0.0453 - n_outputs1_loss: 0.0072\n",
            "Epoch 24: val_loss improved from 0.05564 to 0.05536, saving model to /content/mycar/models/small_model.h5\n",
            "174/174 [==============================] - 349s 2s/step - loss: 0.0525 - n_outputs0_loss: 0.0453 - n_outputs1_loss: 0.0072 - val_loss: 0.0554 - val_n_outputs0_loss: 0.0489 - val_n_outputs1_loss: 0.0064\n",
            "INFO:donkeycar.parts.keras:////////// Finished training in: 2:19:00.558723 //////////\n",
            "INFO:donkeycar.parts.interpreter:Convert model /content/mycar/models/small_model.h5 to TFLite /content/mycar/models/small_model.tflite\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpezjmx73u/assets\n",
            "2025-01-21 02:41:25.149608: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
            "2025-01-21 02:41:25.168787: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 19, Total Ops 32, % non-converted = 59.38 %\n",
            " * 19 ARITH ops\n",
            "\n",
            "- arith.constant:   19 occurrences  (f32: 18, i32: 1)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 5)\n",
            "  (f32: 4)\n",
            "  (f32: 1)\n",
            "INFO:donkeycar.parts.interpreter:TFLite conversion done.\n",
            "INFO:donkeycar.pipeline.database:Writing database file: /content/mycar/models/database.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mycar/models/\n",
        "from google.colab import files\n",
        "files.download(f\"{model_name}.tflite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD-M8m0BUZNx",
        "outputId": "cc5ab077-baab-428b-852b-301957e5620a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mycar/models\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97a1417f-3e9c-478e-9e3e-96a694e2dcdf\", \"small_model.tflite\", 3273056)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ZXObbbCsOW4h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}